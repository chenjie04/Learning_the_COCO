{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "pytorch",
   "display_name": "Python (pytorch)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学习如何使用 MS COCO 数据集   \n",
    "微软发布的 MS COCO 数据集是一个大型图像数据集, 专为目标检测、人体关键点检测、语义分割和字幕生成而设计。本文尝试学习python如何使用该数据集（主要关注目标检测）。"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO 数据格式\n",
    "coco 数据集的标注数据采用json格式存储，基本结构如下："
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"info\": info,\n",
    "    \"images\": [image], #这是一个image的列表，如[image1,image2,....]，\n",
    "    \"annotations\": [annotation], #同理\n",
    "    \"licenses\": [license], #同理\n",
    "    \"categories\": [category]\n",
    "}\n",
    "\n",
    "info{\n",
    "    \"year\": int, \n",
    "    \"version\": str, \n",
    "    \"description\": str, \n",
    "    \"contributor\": str, \n",
    "    \"url\": str, \n",
    "    \"date_created\": datetime,\n",
    "}\n",
    "\n",
    "image{\n",
    "    \"id\": int, \n",
    "    \"width\": int, \n",
    "    \"height\": int, \n",
    "    \"file_name\": str, \n",
    "    \"license\": int, \n",
    "    \"flickr_url\": str, \n",
    "    \"coco_url\": str, \n",
    "    \"date_captured\": datetime,\n",
    "}\n",
    "\n",
    "license{\n",
    "    \"id\": int, \n",
    "    \"name\": str, \n",
    "    \"url\": str,\n",
    "}\n",
    "\n",
    "\n",
    "# 目标检测的annotation\n",
    "annotation{\n",
    "    \"id\": int, \n",
    "    \"image_id\": int, \n",
    "    \"category_id\": int, \n",
    "    \"segmentation\": RLE or [polygon], \n",
    "    \"area\": float, \n",
    "    \"bbox\": [x,y,width,height], \n",
    "    \"iscrowd\": 0 or 1,\n",
    "}\n",
    "\n",
    "categories[{\n",
    "    \"id\": int, \n",
    "    \"name\": str, \n",
    "    \"supercategory\": str,\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO API"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 安装coco api\n",
    "COCO数据集提供了用于加载、解析和可视化的API，本文主要探索python api"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/cocodataset/cocoapi.git   # git、cd等shell命令在jupyter notebook中运行需要在前面加！\n",
    "cd cocoapi/PythonAPI\n",
    "make -j4 install # 这里使用install参数指示将pycocotools安装到conda虚拟环境中的site-packages \n",
    "cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据集准备\n",
    "1. 下载图像数据集（train2017.zip,val2017.zip,test2017.zip）并解压到cocoapi/images文件夹下\n",
    "2. 下载标签数据集（）并解压到cocoapi/annotations文件夹下"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下载图像数据\n",
    "\n",
    "mkdir images\n",
    "cd images\n",
    "\n",
    "wget -c http://images.cocodataset.org/zips/train2017.zip  # --continue, 断点续传\n",
    "wget -c http://images.cocodataset.org/zips/val2017.zip\n",
    "wget -c http://images.cocodataset.org/zips/test2017.zip\n",
    "\n",
    "unzip train2017.zip  \n",
    "unzip val2017.zip\n",
    "unzip test2017.zip\n",
    "\n",
    "#下载标签数据\n",
    "\n",
    "cd ..\n",
    "makdir annotations\n",
    "cd annotations\n",
    "\n",
    "wget -c http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "\n",
    "unzip annotations_trainval2017.zip\n",
    "\n",
    "cd ../../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载必要的依赖包"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from pycocotools.coco import COCO  \n",
    "import numpy as np \n",
    "import skimage.io as io \n",
    "import matplotlib.pyplot as plt \n",
    "import pylab # matplotlib的一个模块，用于二维、三维图像绘制\n",
    "pylab.rcParams['figure.figsize'] = (8.0,10.0) # 设置画布大小\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 指定文件路径"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = './cocoapi/'\n",
    "dataType = 'val2017' # 以验证集为例\n",
    "annFile = '{}/annotations/instances_{}.json'.format(dataDir,dataType)\n",
    "print(annFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初始化COCO类(目标检测)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO(annFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 打印COCO数据类别及其父类"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catIds = coco.getCatIds()\n",
    "#print(\"The total number of categories: \\n\",len(catIds))\n",
    "#print(\"Categories Ids: \\n\",catIds)\n",
    "\n",
    "cats = coco.loadCats(coco.getCatIds()) # [{'supercategory': 'person', 'id': 1, 'name': 'person'},...]\n",
    "#print(\"Categories Names: \\n\",cats)\n",
    "\n",
    "nms = [cat['name'] for cat in cats]\n",
    "#print(\"COCO categories: \\n\",nms)\n",
    "\n",
    "sup_nms = set([cat['supercategory'] for cat in cats]) # 使用set()是为了去除重复项\n",
    "#print(\"COCO supercategories: \\n\",sup_nms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取指定图像"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#获取\"同时包含\"指定类别的图像\n",
    "catIds = coco.getCatIds(catNms=['person','dog','skateboard'])\n",
    "print(\"Number of categories: {}, Category_id: {}\\n\".format(len(catIds),catIds))\n",
    "imgIds = coco.getImgIds(catIds=catIds)\n",
    "print(\"Number of images: {}, Imges ids: {}\\n\".format(len(imgIds),imgIds))\n",
    "imgs = coco.loadImgs(imgIds)\n",
    "print(imgs)\n",
    "#[{'license': 2, 'file_name': '000000549220.jpg', 'coco_url': 'http://images.cocodataset.org/val2017/000000549220.jpg', 'height': 640, 'width': 480, 'date_captured': '2013-11-18 11:01:23', 'flickr_url': 'http://farm4.staticflickr.com/3145/2419498650_fdfe34eb93_z.jpg', 'id': 549220},...]\n",
    "\n",
    "#获取指定ids的图像\n",
    "imgId=[324158]\n",
    "img = coco.loadImgs(imgId)[0] #loadImgs返回的是包含图像dict的list，索引[0]直接选取到dict\n",
    "print(img)\n",
    "\n",
    "#从imgIds中随机选取一张图片\n",
    "img = coco.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载和显示图像"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = {'license': 1, 'file_name': '000000324158.jpg', 'coco_url': 'http://images.cocodataset.org/val2017/000000324158.jpg', 'height': 334, 'width': 500, 'date_captured': '2013-11-19 23:54:06', 'flickr_url': 'http://farm1.staticflickr.com/169/417836491_5bf8762150_z.jpg', 'id': 324158}\n",
    "\n",
    "#使用文件名加载图像\n",
    "I = io.imread('%s/images/%s/%s'%(dataDir,dataType,img['file_name']))\n",
    "#使用url加载图像\n",
    "#I = io.imread(img['coco_url']) # 这应该是到网络上加载图像\n",
    "\n",
    "#plt.axis('off') #不显示坐标尺寸\n",
    "plt.imshow(I)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载和显示实例标签"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(I); plt.axis('off')\n",
    "annIds = coco.getAnnIds(imgIds=img['id'],catIds=catIds,iscrowd=None) #catIds用于显示指定类别的标签\n",
    "anns = coco.loadAnns(annIds)\n",
    "coco.showAnns(anns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 人体关键点"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初始化coco api"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annFile = '{}/annotations/person_keypoints_{}.json'.format(dataDir,dataType)\n",
    "coco_kps = COCO(annFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载和显示关键点标签"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(I); plt.axis('off')\n",
    "ax = plt.gca() #跟画子图有关\n",
    "annIds = coco_kps.getAnnIds(imgIds=img['id'],catIds=catIds,iscrowd=None)\n",
    "anns = coco_kps.loadAnns(annIds)\n",
    "coco_kps.showAnns(anns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图像字幕"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初始化coco api"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annFile = '{}/annotations/captions_{}.json'.format(dataDir,dataType)\n",
    "coco_caps=COCO(annFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载和显示caption标签"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annIds = coco_caps.getAnnIds(imgIds=img['id']);\n",
    "anns = coco_caps.loadAnns(annIds)\n",
    "coco_caps.showAnns(anns)\n",
    "plt.imshow(I); plt.axis('off'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编写COCO数据集的Pytorch接口"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coco数据集目标检测Pytorch接口\n",
    "import os\n",
    "import os.path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F \n",
    "from pycocotools.coco import COCO \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class CocoDetection(data.Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        root (string): Root directory where images are downloaded to.\n",
    "        annFile (string): Path to json annotation file.\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self,root,annFile,img_size=416):\n",
    "        super(CocoDetection,self).__init__()\n",
    "        self.root = root \n",
    "        self.coco = COCO(annFile)\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "\n",
    "        self.img_size = img_size\n",
    "     \n",
    "        COCO_LABEL_MAP = { 1:  1,  2:  2,  3:  3,  4:  4,  5:  5,  6:  6,  7:  7,  8:  8,\n",
    "                   9:  9, 10: 10, 11: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16,\n",
    "                  18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24,\n",
    "                  27: 25, 28: 26, 31: 27, 32: 28, 33: 29, 34: 30, 35: 31, 36: 32,\n",
    "                  37: 33, 38: 34, 39: 35, 40: 36, 41: 37, 42: 38, 43: 39, 44: 40,\n",
    "                  46: 41, 47: 42, 48: 43, 49: 44, 50: 45, 51: 46, 52: 47, 53: 48,\n",
    "                  54: 49, 55: 50, 56: 51, 57: 52, 58: 53, 59: 54, 60: 55, 61: 56,\n",
    "                  62: 57, 63: 58, 64: 59, 65: 60, 67: 61, 70: 62, 72: 63, 73: 64,\n",
    "                  74: 65, 75: 66, 76: 67, 77: 68, 78: 69, 79: 70, 80: 71, 81: 72,\n",
    "                  82: 73, 84: 74, 85: 75, 86: 76, 87: 77, 88: 78, 89: 79, 90: 80}\n",
    "        self.label_map = COCO_LABEL_MAP\n",
    "\n",
    "        self.batch_count = 0\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        coco = self.coco\n",
    "        img_id = self.ids[index]\n",
    "\n",
    "        #==============\n",
    "        # image\n",
    "        # =============\n",
    "        path = coco.loadImgs(img_id)[0]['file_name']\n",
    "        img = Image.open(os.path.join(self.root,path)).convert('RGB')\n",
    "        img = transforms.ToTensor()(img)\n",
    "\n",
    "        # Pad to square resolution\n",
    "        c, h, w = img.shape\n",
    "    \n",
    "\n",
    "        dim_diff = np.abs(h - w)\n",
    "        pad1, pad2 = dim_diff // 2, dim_diff - dim_diff // 2\n",
    "        # Determine padding（左，右，上，下）\n",
    "        pad = (0, 0, pad1, pad2) if h <= w else (pad1, pad2, 0, 0)\n",
    "        # Add padding\n",
    "        img = F.pad(img, pad, \"constant\", value=0)\n",
    "        _, padded_h, padded_w = img.shape\n",
    "\n",
    "        # Resize\n",
    "        img = F.interpolate(img.unsqueeze(0), size=self.img_size, mode=\"nearest\").squeeze(0)\n",
    "\n",
    "        #==============\n",
    "        # labels\n",
    "        # =============\n",
    "        annids = coco.getAnnIds(imgIds=img_id)\n",
    "        anns = coco.loadAnns(annids)\n",
    "\n",
    "        bboxes = []\n",
    "        for i in range(len(anns)):\n",
    "            bbox = [self.label_map[anns[i]['category_id']]-1]\n",
    "            bbox.extend(anns[i]['bbox']) # (x,y,w,h) x和y表示bbox左上角的坐标，w和h表示bbox的宽度和高度\n",
    "            bboxes.append(bbox)\n",
    "        \n",
    "        bboxes = torch.from_numpy(np.array(bboxes))\n",
    "\n",
    "        # Extract coordinates for unpadded + unscaled image（这好像计算出来的是bbox左上和右下两点的坐标）\n",
    "        x1 = (bboxes[:, 1])\n",
    "        y1 = (bboxes[:, 2])\n",
    "        x2 = (bboxes[:, 1] + bboxes[:, 3])\n",
    "        y2 = (bboxes[:, 2] + bboxes[:, 4])\n",
    "        # Adjust for added padding（调整padding后两点的坐标）\n",
    "        x1 += pad[0]\n",
    "        y1 += pad[2]\n",
    "        x2 += pad[1]\n",
    "        y2 += pad[3]\n",
    "        # Returns (x, y, w, h)（重新归一化，（x,y）表示中心点坐标，（w,h）表示bbox的宽和高）\n",
    "        bboxes[:, 1] = ((x1 + x2) / 2) / padded_w\n",
    "        bboxes[:, 2] = ((y1 + y2) / 2) / padded_h\n",
    "        bboxes[:, 3] *= 1 / padded_w\n",
    "        bboxes[:, 4] *= 1 / padded_h\n",
    "\n",
    "        #bboxes的格式为(category,x,y,w,h)\n",
    "        targets = torch.zeros((len(bboxes), 6))\n",
    "        targets[:, 1:] = bboxes\n",
    "\n",
    "\n",
    "        return img, targets\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"将数据和标签拼接成batch\"\"\"\n",
    "        imgs, targets = list(zip(*batch))\n",
    "        # Remove empty placeholder targets\n",
    "        targets = [bboxes for bboxes in targets if bboxes is not None]\n",
    "        # Add sample index to targets\n",
    "        for i, bboxes in enumerate(targets):\n",
    "            bboxes[:, 0] = i # 使用索引表示哪些bboxes对应batch中的那张图片 此时bboxes的格式为(index,category,x,y,w,h)\n",
    "        targets = torch.cat(targets, 0) #拼接\n",
    "    \n",
    "        imgs = torch.stack([img for img in imgs])\n",
    "        self.batch_count += 1\n",
    "        return imgs, targets\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用Pytorch加载一张图片并显示检测框"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = './cocoapi/images/val2014'\n",
    "annFile = './cocoapi/annotations/instances_val2014.json'\n",
    "\n",
    "dataset = CocoDetection(root=dataDir,annFile=annFile)\n",
    "# image, label = dataset[5]\n",
    "# print (image.size())\n",
    "# print (label)\n",
    "\n",
    "dataset_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                           batch_size=1, \n",
    "                                           shuffle=True,\n",
    "                                           collate_fn=dataset.collate_fn)\n",
    "\n",
    "# When iteration starts, queue and thread start to load data from files.\n",
    "data_iter = iter(dataset_loader)\n",
    "\n",
    "# Mini-batch images and labels.\n",
    "images, labels = data_iter.next() # labels: (index,category,x,y,w,h)\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "b, c, h, w = images.shape\n",
    "img = images.mul(255).byte()\n",
    "img = img.cpu().numpy().squeeze(0).transpose((1, 2, 0))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "COCO_REVERSE_LABEL_MAP = { 1:  1,  2:  2,  3:  3,  4:  4,  5:  5,  6:  6,  7:  7,  8:  8,\n",
    "                   9:  9, 10: 10, 11: 11, 12: 13, 13: 14, 14: 15, 15: 16, 16: 17,\n",
    "                  17: 18, 18: 19, 19: 20, 20: 21, 21: 22, 22: 23, 23: 24, 24: 25,\n",
    "                  25: 27, 26: 28, 27: 31, 28: 32, 29: 33, 30: 34, 31: 35, 32: 36,\n",
    "                  33: 37, 34: 38, 35: 39, 36: 40, 37: 41, 38: 42, 39: 43, 40: 44,\n",
    "                  41: 46, 42: 47, 43: 48, 44: 49, 45: 50, 46: 51, 47: 52, 48: 53,\n",
    "                  49: 54, 50: 55, 51: 56, 52: 57, 53: 58, 54: 59, 55: 60, 56: 61,\n",
    "                  57: 62, 58: 63, 59: 64, 60: 65, 61: 67, 62: 70, 63: 72, 64: 73,\n",
    "                  65: 74, 66: 75, 67: 76, 68: 77, 69: 78, 70: 79, 71: 80, 72: 81,\n",
    "                  73: 82, 74: 84, 75: 85, 76: 86, 77: 87, 78: 88, 79: 89, 80: 90}\n",
    "\n",
    "bboxes = labels.cpu().numpy().squeeze()\n",
    "for i in range(len(bboxes)):\n",
    "    x1 = int(w * (bboxes[i][2]-bboxes[i][4]/2))  \n",
    "    y1 = int(h * (bboxes[i][3]-bboxes[i][5]/2))\n",
    "    x2 = int(w * (bboxes[i][2]+bboxes[i][4]/2))  \n",
    "    y2 = int(h * (bboxes[i][3]+bboxes[i][5]/2))\n",
    "\n",
    "    cv2.rectangle(img, (x1,y1), (x2,y2), (255, 0, 0), thickness=1)\n",
    "    cv2.circle(img, (int(w*bboxes[i][2]),int(h*bboxes[i][3])), 1, (0,0,255), thickness=2)\n",
    "    \n",
    "    catId = COCO_REVERSE_LABEL_MAP[int(bboxes[i][1])-1]\n",
    "    cat = coco.loadCats(catId)\n",
    "    label = cat[0]['name']\n",
    "    print(label)\n",
    "    t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1 , 1)[0]\n",
    "    x3, y3 = x1+t_size[0]+3, y1+t_size[1]+4\n",
    "    cv2.rectangle(img, (x1,y1), (x3,y3), (255, 0, 0), thickness=-1)\n",
    "    cv2.putText(img, label, (x1, y1 + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [225,255,255], 1);\n",
    "\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 直接使用coco api加载图像并显示检测框"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "dataDir = \"./cocoapi/images/val2017\"\n",
    "annFile = \"./cocoapi/annotations/instances_val2017.json\" \n",
    "coco = COCO(annFile)\n",
    "catIds = coco.getCatIds(catNms=['person','dog','skateboard'])\n",
    "imgIds = coco.getImgIds(catIds=catIds )\n",
    "imgId = imgIds[np.random.randint(0,len(imgIds))]\n",
    "img = coco.loadImgs(imgId)[0]\n",
    "annIds = coco.getAnnIds(imgIds=imgId,iscrowd=None)\n",
    "anns = coco.loadAnns(annIds)\n",
    "\n",
    "\n",
    "img = cv2.imread('%s/%s'%(dataDir,img['file_name']))\n",
    "print(img.shape)\n",
    "for i in range(len(anns)):\n",
    "    bbox = anns[i]['bbox']\n",
    "    x1 = int(bbox[0])  \n",
    "    y1 = int(bbox[1])\n",
    "    x2 = int((bbox[0] + bbox[2]))  \n",
    "    y2 = int((bbox[1] + bbox[3]))\n",
    "    cv2.rectangle(img, (x1,y1), (x2,y2), (255, 0, 0), thickness=2)\n",
    "    cv2.circle(img, (int((x1+x2)/2),int((y1+y2)/2)), 1, (0,0,255), thickness=2)\n",
    "    \n",
    "    catId = anns[i]['category_id']\n",
    "    cat = coco.loadCats(catId)\n",
    "    label = cat[0]['name']\n",
    "    t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1 , 1)[0]\n",
    "    x3, y3 = x1+t_size[0]+3, y1+t_size[1]+4\n",
    "    cv2.rectangle(img, (x1,y1), (x3,y3), (255, 0, 0), thickness=-1)\n",
    "    cv2.putText(img, label, (x1, y1 + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [225,255,255], 1);\n",
    "plt.imshow(img)\n",
    "# coco.showAnns(anns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO数据集目标检测评价指标"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 检测结果格式\n",
    "目标检测需要同时判断目标是否存在以及目标的位置，因此预测结果中必须包含“类别ID”以及bbox的坐标（一般用中心点坐标表示，也有可能用左上角坐标表示，COCO数据集用的是左上角坐标，本文将其转换成了中心点坐标）和大小（用宽度和高度表示）。同时，为了评估误判的风险，每一个预测框增加一个置信度分数（score）表示模型对该预测的信心。因此，预测结果具备以下结构："
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[{\n",
    "    \"image_id\": int, \n",
    "    \"category_id\": int, \n",
    "    \"bbox\": [x,y,width,height], \n",
    "    \"score\": float,\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 什么是好的检测结果？\n",
    "首先，一个好的检测结果必须能够正确预测目标的类别，类别错了一切白搭。\n",
    "其次，检测的位置信息必须准确，也就是检测框必须尽可能地与目标贴合。“贴合度”往往采用IoU（交并比）来表示，交并比就是检测框与Ground Truth的重合面积（交集）与两者全部的面积（并集，不重复计算重合部分面积）的比值。\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![图片来源见水印](images_/IoU.jpg \"图片来源见水印\")\n",
    "\n",
    "*图片来源见水印*"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COCO数据集中的目标检测评价指标\n",
    "在COCO数据集中，主要采用以下12种指标评价目标检测模型的性能。"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images_/Det_metrics.PNG \"目标检测指标\")\n",
    "\n",
    "*注：[0.50:0.05:0.95] 表示从0.50到0.95以0.05为间隔的序列 (0.5, 0.55, 0.6, ..., 0.9, 0.95)*\n",
    "\n",
    "*AP (averaged across all 10 IoU thresholds and all 80 categories)*"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Precision (AP)\n",
    "首先，在目标检测任务中，有些使用场景对位置的准确度要求不高，有些则要求精确定位。位置信息精确度通过设置不同IoU阈值实现，COCO数据集设定的阈值为 (0.5, 0.55, 0.6, ..., 0.9, 0.95)。给定某个阈值，如果检测框与Ground-Truth的Iou超过该阈值则视为检测成功，这样就可以计算出该IoU下模型的性能。\n",
    "\n",
    "其次，需要考虑类别均衡的稳定，有些使用场景不同类别的目标检测的重要性不同（误检的影响大小不同），因此需要公平地评价检测模型在各个类别上的性能。先给定一个IoU阈值，然后对所有的检测结果和Ground-Truth按类别分类，并对每一个类别计算出一个准确率（AP），最后对所有类比的准确率取平均值（mAP），这就是这个模型在该IoU下的性能。\n",
    "\n",
    "COCO数据集的AP和AR还需要将多个IoU下的性能表现做平均。\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 传统 mAP 计算过程\n",
    "给定IoU阈值，计算mAP。\n",
    "\n",
    "1 定义所有的检测结果为dts，Ground-Truth为gts，遍历目标类别，选取每一类别的检测结果和Ground-Truth（_dts,_gts）\n",
    "\n",
    "2 在该类别下，遍历图片，选取每一图片的检测结果和Ground-Truth（_dts_,_gts_）。\n",
    "\n",
    "3 对该图品的检测结果（_dts_）依据置信度分数（score）排序\n",
    "\n",
    "4 依序遍历_dts_中所有的dt，计算dt与_gts_内所有Ground-Truth的IoU，如果最大的IoU大于阈值，视为检测成功，算作TP（True Positive），并且最大IoU对应的gt被视为匹配成功。如果该dt与所有gt的IOU都没超过阈值，自然就是FP（False Positive）\n",
    "\n",
    "5 同时，每当一个gt被检测成功后，都会从_gts_和_gts中“被取走”，以免后续的检测结果重复匹配\n",
    "\n",
    "6 如果有多个检测结果都与同一个gt匹配，那么分数最高的那个会被算为TP，其余均为FP。所以所有在_dts中但不在TPs中的dt都属于FP\n",
    "\n",
    "7 由于被匹配过的gt都会“被取走”，因此_gts中剩下的就是没有被匹配上的FN（False Negative） \n",
    "\n",
    "8 precision = TP / (TP + FP), recall = TP / (TP + FN)\n",
    "\n",
    "9 在每一个类别下，对排序检测结果进行不同的“截断”（取前n个）可以计算出一组准确率和召回率，从而得到准确率_召回率曲线，计算出平均准确率AP(average precision)\n",
    "\n",
    "10 对所有类别的AP取平均得到mAP"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 个人理解的mAP计算过程伪代码，实际上还是直接使用MS COCO官方提供的api吧\n",
    "def Evaluation(dts,gts,iou_thre):\n",
    "    average_precisions = []\n",
    "    for cat in enumerate(categories):\n",
    "        # 对检测结果进行截断，只取前maxDet个检测结果，用于计算average precision\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        for maxDet in enumerate(maxDets): #maxDets=[10,20,..,100]\n",
    "            _dts = dts.get_dts_per_cat(cat) #获取某一类别的检测结果\n",
    "            _gts = gts.get_gts_per_cat(cat) #获取某一类别的Ground_Truth\n",
    "            TPs = []  #真阳性\n",
    "            for img in enumerate(images):\n",
    "                _dts_ = _dts.get_dts_per_cat(img) #获取某一图片的检测结果\n",
    "                _gts_ = _gts.get_gts_per_cat(img) #获取某一图片的Ground_Truth\n",
    "                _dts_.sort(reverse=True)\n",
    "                _dts_ = _dts_.get_top_K(k=maxDet) #只取前maxDet个检测结果\n",
    "                for dt in _dts_:\n",
    "                    #get the max iou and the corresponding gt\n",
    "                    max_iou = max([iou(dt,gt) for gt in _gts_])\n",
    "                    max_iou_gt = argmax([iou(dt,gt) for gt in _gts_])\n",
    "                    if max_iou >= iou_thre:\n",
    "                        TPs.append(dt)\n",
    "                        # never match one GT twice\n",
    "                        _gts_.pop(max_iou_gt) \n",
    "                        _gts.pop(max_iou_gt)\n",
    "\n",
    "            FPs = [dt for dt in _dts if not dt in TPs]\n",
    "            FNs = _gts\n",
    "\n",
    "            TP = len(TPs)\n",
    "            FP = len(FPs)\n",
    "            FN = len(FNs)\n",
    "            precision = TP / (TP + FP)\n",
    "            recall = TP / (TP + FN)\n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "        # get average precision\n",
    "        # plot a precision-recall curve, plotting precision p(r) as a function of recall r. \n",
    "        # Average precision computes the average value of p(r) over the interval from r=0 to r=1.\n",
    "        curve = plot_precision_recall_curve(precisions,recalls)\n",
    "        average_precision = sum(p(k)*r(k)) # k=1,...n\n",
    "        average_precisions.append(average_precision)\n",
    "    \n",
    "    mAP = average_precisions.mean()\n",
    "\n",
    "    return mAP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "心烦，直接使用COCO官方提供的api吧。。。只要提供符合格式要求的结果文件就行"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用COCO API评估目标检测模型性能"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annType = 'bbox'\n",
    "prefix = 'instances'\n",
    "print(\"Running demo for *%s* results.\"%(annType))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初始化COCO Ground-truth API"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = './cocoapi'\n",
    "dataType = 'val2014'\n",
    "annFile = '%s/annotations/%s_%s.json'%(dataDir,prefix,dataType)\n",
    "cocoGt = COCO(annFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初始化COCO检测结果API"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resFile = '%s/results/%s_%s_fake%s100_results.json'%(dataDir,prefix,dataType,annType)\n",
    "cocoDt = cocoGt.loadRes(resFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取图像ID"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgIds = sorted(cocoGt.getImgIds())\n",
    "imgIds = imgIds[0:100]\n",
    "imgId = imgIds[np.random.randint(100)]\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 运行评估"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocoEval = COCOeval(cocoGt,cocoDt,annType)\n",
    "cocoEval.params.imgIds = imgIds\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ]
  }
 ]
}